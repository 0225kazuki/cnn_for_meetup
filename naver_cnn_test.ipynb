{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import sqlite3\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in glob.glob(\"2ch/*\"):\n",
    "    img = Image.open(i)\n",
    "    img = img.resize((100,100))\n",
    "    plt.figure()\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2ch/125.jpg\n",
      "2ch/156.jpg\n",
      "2ch/159.jpg\n",
      "2ch/194.jpg\n",
      "2ch/235.jpg\n",
      "2ch/258.jpg\n",
      "2ch/270.jpg\n",
      "2ch/393.jpg\n",
      "2ch/462.jpg\n",
      "2ch/487.jpg\n",
      "2ch/502.jpg\n",
      "2ch/664.jpg\n",
      "2ch/805.jpg\n",
      "2ch/818.jpg\n",
      "2ch/863.jpg\n",
      "2ch/923.jpg\n",
      "2ch/937.jpg\n",
      "2ch/954.jpg\n",
      "2ch/979.jpg\n",
      "2ch/996.jpg\n",
      "2ch/1116.jpg\n",
      "2ch/1157.jpg\n",
      "2ch/1186.jpg\n",
      "2ch/1231.jpg\n",
      "2ch/1272.jpg\n",
      "2ch/1342.jpg\n",
      "2ch/1396.jpg\n",
      "2ch/1702.jpg\n",
      "2ch/1794.jpg\n",
      "2ch/1922.jpg\n",
      "2ch/1946.jpg\n",
      "2ch/1973.jpg\n",
      "2ch/1974.jpg\n",
      "2ch/1977.jpg\n",
      "2ch/2071.jpg\n",
      "2ch/2076.jpg\n",
      "2ch/2245.jpg\n",
      "2ch/2288.jpg\n",
      "2ch/2314.jpg\n",
      "2ch/2400.jpg\n",
      "2ch/2434.jpg\n",
      "2ch/2454.jpg\n",
      "2ch/2584.jpg\n",
      "2ch/2695.jpg\n",
      "2ch/2832.jpg\n",
      "2ch/2834.jpg\n",
      "2ch/2852.jpg\n",
      "2ch/2857.jpg\n",
      "2ch/2920.jpg\n",
      "2ch/3361.jpg\n",
      "2ch/3434.jpg\n",
      "2ch/3608.jpg\n",
      "2ch/3672.jpg\n",
      "2ch/3705.jpg\n",
      "2ch/3792.jpg\n",
      "2ch/3893.jpg\n",
      "2ch/4016.jpg\n",
      "2ch/4062.jpg\n",
      "2ch/4074.jpg\n",
      "2ch/4100.jpg\n",
      "2ch/4103.jpg\n",
      "2ch/4160.jpg\n",
      "2ch/4261.jpg\n",
      "2ch/4331.jpg\n",
      "2ch/4366.jpg\n",
      "2ch/4443.jpg\n",
      "2ch/4494.jpg\n",
      "2ch/4549.jpg\n",
      "2ch/4605.jpg\n",
      "2ch/4615.jpg\n",
      "2ch/4724.jpg\n",
      "2ch/4727.jpg\n",
      "2ch/4811.jpg\n",
      "2ch/4817.jpg\n",
      "2ch/4885.jpg\n",
      "2ch/4933.jpg\n",
      "2ch/5090.jpg\n",
      "2ch/5096.jpg\n",
      "2ch/5174.jpg\n",
      "2ch/5264.jpg\n",
      "2ch/5320.jpg\n",
      "2ch/5372.jpg\n",
      "2ch/5612.jpg\n",
      "2ch/5731.jpg\n",
      "2ch/5754.jpg\n",
      "2ch/5805.jpg\n",
      "2ch/5849.jpg\n",
      "2ch/5932.jpg\n",
      "2ch/5987.jpg\n",
      "2ch/6006.jpg\n",
      "2ch/6051.jpg\n",
      "2ch/6093.jpg\n",
      "2ch/6296.jpg\n",
      "2ch/6357.jpg\n",
      "2ch/6410.jpg\n",
      "2ch/6473.jpg\n",
      "2ch/6479.jpg\n",
      "2ch/6675.jpg\n",
      "2ch/6759.jpg\n",
      "2ch/6787.jpg\n",
      "2ch/6847.jpg\n",
      "2ch/6917.jpg\n",
      "2ch/6928.jpg\n",
      "2ch/7278.jpg\n",
      "2ch/7287.jpg\n",
      "2ch/7387.jpg\n",
      "2ch/7409.jpg\n",
      "2ch/7515.jpg\n",
      "2ch/7628.jpg\n",
      "2ch/7634.jpg\n",
      "2ch/7698.jpg\n",
      "2ch/7717.jpg\n",
      "2ch/7774.jpg\n",
      "2ch/7778.jpg\n",
      "2ch/7793.jpg\n",
      "2ch/7820.jpg\n",
      "2ch/7839.jpg\n",
      "2ch/7849.jpg\n",
      "2ch/7946.jpg\n",
      "2ch/8201.jpg\n",
      "2ch/8215.jpg\n",
      "2ch/8427.jpg\n",
      "2ch/8453.jpg\n",
      "2ch/8554.jpg\n",
      "2ch/8643.jpg\n",
      "2ch/8676.jpg\n",
      "2ch/8715.jpg\n",
      "2ch/8777.jpg\n",
      "2ch/8986.jpg\n",
      "2ch/9299.jpg\n",
      "2ch/9420.jpg\n",
      "2ch/9544.jpg\n",
      "2ch/9583.jpg\n",
      "2ch/9634.jpg\n",
      "2ch/9856.jpg\n",
      "2ch/9875.jpg\n",
      "2ch/9985.jpg\n",
      "2ch/10057.jpg\n",
      "2ch/10078.jpg\n",
      "2ch/10107.jpg\n",
      "2ch/10176.jpg\n",
      "2ch/10301.jpg\n",
      "2ch/10365.jpg\n",
      "2ch/10366.jpg\n",
      "2ch/10426.jpg\n",
      "2ch/10526.jpg\n",
      "2ch/10641.jpg\n",
      "2ch/10765.jpg\n",
      "2ch/10818.jpg\n",
      "2ch/10848.jpg\n",
      "2ch/11013.jpg\n",
      "2ch/11163.jpg\n",
      "2ch/11297.jpg\n",
      "2ch/11332.jpg\n",
      "2ch/11371.jpg\n",
      "2ch/11374.jpg\n",
      "2ch/11387.jpg\n",
      "2ch/11502.jpg\n",
      "2ch/11657.jpg\n",
      "2ch/11765.jpg\n",
      "2ch/11831.jpg\n",
      "2ch/11835.jpg\n",
      "2ch/11955.jpg\n",
      "2ch/11991.jpg\n",
      "2ch/12041.jpg\n",
      "2ch/12057.jpg\n",
      "2ch/12149.jpg\n",
      "2ch/12173.jpg\n",
      "2ch/12325.jpg\n",
      "2ch/12531.jpg\n",
      "2ch/12541.jpg\n",
      "2ch/12626.jpg\n",
      "2ch/12687.jpg\n",
      "(12618, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.empty((0,100,100,3), float)\n",
    "y_train = []\n",
    "conn = sqlite3.connect(\"naver_views.db\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "for i in glob.glob(\"2ch/*\"):\n",
    "    \n",
    "    # 100*100にトリムして正規化\n",
    "    img = Image.open(i)\n",
    "    img = img.resize((100,100))\n",
    "    img_array = np.array(img, 'f')\n",
    "    img_array /= 255.\n",
    "    \n",
    "    # グレースケールは除外\n",
    "    if len(img_array.shape) == 2:\n",
    "        print(i);continue\n",
    "\n",
    "    # dbからview数取得\n",
    "    cur.execute(\"\"\"select view from views where id = {}\"\"\".format(int(i.split('.')[0].split(\"/\")[-1])))\n",
    "    view = cur.fetchall()[0][0]\n",
    "\n",
    "    # 追加\n",
    "    x_train = np.append(x_train,img_array.reshape(-1,100,100,3),axis=0)\n",
    "    y_train.append(view)\n",
    "    \n",
    "print(x_train.shape)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"naver_dataset.dump\",\"wb\") as f:\n",
    "    pickle.dump((x_train,y_train),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11618, 2) (1000, 2)\n"
     ]
    }
   ],
   "source": [
    "one_hot_y_train = []\n",
    "for e,i in enumerate(y_train):\n",
    "    if i > 10000:\n",
    "        one_hot_y_train.append([1.,0.])\n",
    "    else:\n",
    "        one_hot_y_train.append([0.,1.])\n",
    "    \n",
    "Y_train = np.array(one_hot_y_train)[:-1000]\n",
    "X_train = x_train[:-1000]\n",
    "Y_test = np.array(one_hot_y_train)[-1000:]\n",
    "X_test = x_train[-1000:]\n",
    "\n",
    "print(Y_train.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 100, 100, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 98, 98, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 98, 98, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 49, 49, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 49, 49, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 47, 47, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 47, 47, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 23, 23, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 21, 21, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 21, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               6554112   \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 6,842,146\n",
      "Trainable params: 6,842,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 11618 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "11618/11618 [==============================] - 692s - loss: 0.6691 - acc: 0.6256 - val_loss: 0.6457 - val_acc: 0.6520\n",
      "Epoch 2/5\n",
      "11618/11618 [==============================] - 691s - loss: 0.6578 - acc: 0.6271 - val_loss: 0.6451 - val_acc: 0.6520\n",
      "Epoch 3/5\n",
      "11618/11618 [==============================] - 692s - loss: 0.6529 - acc: 0.6264 - val_loss: 0.6494 - val_acc: 0.6520\n",
      "Epoch 4/5\n",
      "11618/11618 [==============================] - 706s - loss: 0.6509 - acc: 0.6282 - val_loss: 0.6652 - val_acc: 0.6270\n",
      "Epoch 5/5\n",
      "11618/11618 [==============================] - 708s - loss: 0.6519 - acc: 0.6297 - val_loss: 0.6483 - val_acc: 0.6520\n"
     ]
    }
   ],
   "source": [
    "nb_classes=2\n",
    "\n",
    "# CNNを構築\n",
    "model = Sequential()\n",
    "\n",
    "# conv 3*3 -> 32 channels\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "# Max pooling 2*2\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 全結合 512\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# 全結合 10\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "batch_size = 100\n",
    "nb_epoch = 5\n",
    "history = model.fit(X_train, Y_train,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=nb_epoch,\n",
    "                            verbose=1,\n",
    "                            validation_data=(X_test, Y_test),\n",
    "                            shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
